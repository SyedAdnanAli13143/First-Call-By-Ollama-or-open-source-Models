# First-Call-By-Ollama-or-open-source-Models

This project demonstrates how to use a locally running large language model with Ollama (llama3.2) in Python using Jupyter notebooks.

Instead of relying on API keys or cloud services, the OpenAI client is configured to point to a local Ollama instance. Once Ollama is installed and running, the notebook can send prompts directly to the local model using the same message format commonly used by OpenAI APIs.

The project includes:

Fetching and cleaning website content with BeautifulSoup

Building clear system and user prompts

Summarizing website text using a local LLM

Displaying results cleanly in Jupyter using Markdown

Itâ€™s designed as a learning-friendly starting point for experimenting with local LLMs, prompt design, and basic web content analysis.
